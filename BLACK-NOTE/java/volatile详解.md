# volatile底层实现

## 硬件层面知识

### 缓存与缓存行

**cpu缓存**：一般在 cpu 集成了多级缓存的结构，常见的为三级缓存的结构。

L1 cache：分为数据缓存和指令缓存，逻辑核独占 

L2 cache：物理核独占，逻辑核共享 

L3 cache：所有物理核共享 

空间大小排序：L3 > L2 > L1

速度快慢排序：L3 < L2 < L1

**缓存行**（cache line）：一般大小为 64byte，缓存由若干个缓存行组成。通常，CPU 在操作数据的时候都是以缓存行为最小单位对缓存进行数据操作

查看缓存行大小：

```cmd
[root@centos ~]# cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
```

缓存行的结构：|valid|tag|data|

+ valid：标志该缓存行是否有效
+ tag：数据的内存地址
+ data：存放实际的数据

### MESI 缓存一致性协议

MESI 的四个状态：

+ Modified - 被修改

  该缓存行数据已修改，且未写回主存（在未来的某个时刻写回），写回之后状态会变成 Exclusive 

+ Exclusive - 独享的

  该缓存行数据最新（和主存同步），其他缓存行更新缓存行后，状态会转为 Shared。或者该缓存行数据修改后，状态会转为 Modified

+ Shared - 共享的

  该数据被多个 CPU 缓存，且各个缓存行中的数据与主存都一致，当有一个缓存行数据发送改变的时候，该缓存行状态转为 Modified，其他缓存行状态变为 Invalid

+ Invalid - 无效的

  无效的缓存行，需要重新读取主存中的数据

状态转换表：

<img src='volatile_img\MESI事件表.png' width='900px'/>



举例状态转换过程：

假设有两个 CPU，分别为 CPU1 和 CPU2，对变量 a 进行操作

首先 CPU1 发起事件 Local Write，对 a++（对数据的修改操作），此时如果 CPU1 之前是没有加载过 a 的内存地址的话，则此时的缓存行状态为 I，首先 CPU1 会将 a 的数据从内存中读取出来，在缓存中执行++后，缓存行的状态变为 M。然后，CPU2 发起事件 Local Read（对变量的读取操作），CPU1 在总线上嗅探到这个读请求后，会先将自己的缓存行中的数据回写到主存中，然后再内存总线上放一份缓存行的拷贝作为应答（交由CPU2读取），最后将自身的缓存行状态修改为 S。此时 CPU1 和 CPU2 经过这一轮操作后的缓存行状态都为 S。

## volatile使用lock前缀指令保证可见性

lock是前缀，有这个前缀的指令将进行原子操作

变量被 volatile 修饰，在汇编指令层面实际上是加上了个 lock 指令（可以将代码转换为汇编指令进行查看验证）

加上 lock 指令后，就会触发使用 MESI 缓存一致性协议。（加锁操作是由高速缓存锁或总线锁来处理 ）

过程描述：

假设有两个线程 A 和 B，对 valatile int a 进行操作

首先 线程 A 要对 a 进行写操作，发出了 lock 指令（锁缓存行），同时让线程 B 的缓存行失效，然后线程 A 向主存写回新值 a

线程 B 对 a 进行读值，发现对应地址的缓存行被锁了，等待锁的释放，缓存一致性协议会保证它读取到最新的值 

> 注意：上面的描述看上去的意思像是可以保证 java 中对 i++ 的线程安全，其实不是，i++ 本身不是一个原子操作，大致步骤可以分为三步
>
> 1. 获取 i 的值
> 2. 对这个值进行+1
> 3. 将这个值会写回 i 的内存地址
>
> 建立在上面的过程描述，如果线程 A 和 线程 B 对 i 同时执行自增操作，有可能出现这种情况（假设 a 在主存中的值为 0）
>
> 1. 线程 A 发出 lock 指令对 a 读值，线程 A 得到了 a 的值，记录在缓存行中（此时 a = 0）
> 2. 线程 B 发出 lock 指令对 a 读值，线程 B 得到了 a 的值，记录在缓存行中（此时 a = 0）
> 3. 线程 A 对得到的 a 值执行自增（此时 a = 1）
> 4. 线程 B 对得到的 a 值执行自增（此时 a = 1）
> 5. 回写主存，最终得到的 a 的值为 1
>
> 在这个过程中，也许会有这个疑惑，第三步的时候 A 对 a 执行自增后，由于MESI，B 的缓存行应该失效了，B 需要对 a 进行重新读值，B 的缓存行确实已经失效，但是 B 的读值指令已经在第二步发生了，所以是不需要重新读值的，只能做加法指令，以上。

以上，可以清楚了解了 volatile 是通过 lock 前缀指令以及 MESI 来保证的可见性。总所周知，volatile 还具有保证有序性，那是如何保证的？

## JVM生成内存屏障指令保证有序性

### 内存屏障的概念

硬件层面的内存屏障可以分为两种

+ 读屏障（load Barrier）
+ 写屏障（store Barrier）

作用

+ 禁止指令重排序

  什么是指令重排序？

  >现代CPU的速度越来越快，为了充分的利用CPU，在编译器和CPU执行期，都可能对指令重排。

  例子：Object o = new Object() 大致就会分成三个指令

  1. 申请一块内存空间
  2. 初始化这个对象（数据存放在内存空间）
  3. 设置引用 o 指向刚分配的内存地址

  如果没有加上 volatile 的话，jvm 是可以对这三个指令进行优化的，步骤2 和 步骤3 是可以调换位置的。

  假设优化后的顺序是 1、3、2，那么线程 A 执行到 3 的时候，其实对象还没有开始初始化，那再来一个线程 B 去读取 o 引用到的内存空间，就会发生错误。

  所以，有时候为了避免出现这种错误，就需要禁止指令重排序。

+ 将高速缓存中的数据回写主存或者更新高速缓存中的数据

## volatile语义如何实现内存屏障

java 代码中，变量被 volatile 修饰后，编译器在生成字节码的时候，会在指令序列中插入内存屏障禁止重排序。

+ 写操作时内存屏障

  StoreStore

  volatile写操作（禁止指令重排）

  StoreLoad

+ 读操作时内存屏障

  LoadLoad

  volatile读操作（禁止指令重排）

  LoadStore

以上，实现有序性就是通过加上读写屏障完成的。

## 其他

volatile 的使用场景：

1. DCL（双重校验锁）
2. JUC 包中频繁使用了 volatile



volatile 和 synchronized 的区别

+ 从语法角度：volatile 是修饰成员变量的，而 synchronized 是修饰方法或者方法内部的代码块
+ 从原子性、可见性、有序性的角度：volatile保证有序和可见性，synchronized 保证可见性、原子性、有序性
+ synchronized 是串行化执行，volatile不是